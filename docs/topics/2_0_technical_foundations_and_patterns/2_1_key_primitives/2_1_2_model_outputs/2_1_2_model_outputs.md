<!-- 
 Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
 SPDX-License-Identifier: CC-BY-SA-4.0
 -->

# Responses: Understanding Model Outputs

**Content Level: 200**



## Suggested Pre-Reading

- [Key Primitives](../index.md)
- [Prompts](../2_1_1_prompt/2_1_1_prompt.md)

## TL;DR

Responses are outputs generated by AI models in reaction to prompts.
They can be either deterministic (consistent outputs for identical inputs) or non-deterministic (varied outputs with controlled randomness), with most LLMs being non-deterministic while image generators typically use seed values for reproducibility.
Responses come in various formats including plain text, structured data (JSON/XML), code, and markdown-formatted content.
The choice between determinism levels and output formats significantly impacts application design - use deterministic approaches for systems requiring consistency and reproducibility, and non-deterministic approaches for applications needing creativity and natural variation.
Understanding how to effectively work with these outputs and leveraging parameters like temperature to control randomness is important for building reliable and effective GenAI applications.

## Responses: Understanding Model Outputs
Responses are the outputs generated by AI models in reaction to prompts.
Understanding the nature and characteristics of these responses is important for building reliable and effective GenAI applications.

### Deterministic vs. Non-deterministic Outputs
Model parameters and the type of the model determine whether the model is deterministic or non-deterministic:

 - **Deterministic**: The same prompt will always produce the same response. 
 - **Non-deterministic**: Responses have controlled randomness to enable creativity or diversity

Most LLMs are non-deterministic, i.e., even for the same prompt and parametrization, they will produce different outputs.
While model parameters like temperature and other sampling parameters (like top_p, top_k) control the predictability and creativity in model outputs, even if these parameters are exactly the same for the same prompt, the output may differ.
Nevertheless, these parameters can be used to produce more focused, predictable responses.
The largest group of deterministic LLMs are image generators: They typically have a seed parameter and for the same model, prompt, and parameters (including the seed value), they produce the exact same image.
This is illustrated below for the prompt “Icon with dwarf house with a garden in comic style” with Amazon Nova Canvas and different seed values:

<div style="margin:auto;text-align:center;width:100%;">
  <img src="./assets/DwarfHouses.png" alt="Results of a single prompt with different seeds for Nova Canvas" width="1000" style="margin: auto; text-align: center;"/>
</div>

### Response Formats
Models can generate responses in various text formats such as:

 - Plain text narratives
 - Structured JSON or XML
 - Programming code
 - Markdown-formatted content
 - Lists, tables, and other structured format

Function calling or JSON mode capabilities allow for more reliable structured outputs that can be directly parsed and used in downstream applications.
Aside from textual responses, LLMs can also generate images (e.g., PNG or JPG) or videos (e.g., MP4).

## Making it practical

Understanding how to effectively work with model outputs is important when building GenAI applications.
The type of output you need and how you handle it will significantly impact your application architecture and user experience.

### Choosing Between Deterministic and Non-deterministic Outputs

When designing your application, consider whether you need consistent outputs or creative variety:

- **Use deterministic outputs when**:
  - Building critical systems that require reproducible results
  - Creating automated testing scenarios where consistency is important
  - Implementing solutions where audit trails or explanations are needed
  - Generating reference materials or documentation

- **Use non-deterministic outputs when**:
  - Building creative applications like content generators or brainstorming tools
  - Creating conversational agents that need to sound natural and varied
  - Generating multiple alternatives for users to choose from

In practice, many GenAI applications benefit from controlled non-determinism.
For example, a customer service chatbot might use lower temperature settings (0.1-0.3) to encourage reliable and factual responses, while a creative writing assistant might use higher settings (0.7-0.9) to encourage novel outputs.

### Working with Response Formats in Production

The format you choose for model outputs will determine how your application processes and presents information:

- **Plain text** is suitable for simple conversational interfaces but requires more post-processing for structured data extraction.
  
- **Structured formats** (JSON/XML) are invaluable when integrating with existing systems. Using function calling or JSON mode significantly reduces parsing errors and allows direct integration with APIs and databases.
  
- **Code generation** outputs should typically be validated before execution, especially in production environments. Consider implementing safety measures like sandboxed environments or human review.

- **Markdown-formatted content** works well for content that will be displayed in web applications with minimal additional rendering work.

### Practical Implementation Tips

1. **Implement fallback mechanisms** to handle unexpected outputs, especially with non-deterministic models.

2. **Cache responses** for identical prompts in deterministic scenarios to optimize performance and costs.

3. **Set appropriate timeout parameters** based on expected response lengths and complexity.

4. **Use streaming responses** for better user experience in applications where immediate feedback is important.

5. **Post-process outputs** as needed, such as formatting, validation, or sanitization before presenting to users or downstream systems.

6. **For image generation**, consider storing seed values that produce desirable outputs to recreate them later, or to make controlled variations by slightly modifying the seed.

7. **Test outputs across model versions** as models may be updated over time, affecting response characteristics even with identical parameters.

When building production systems, consider how response formats align with your application's data flow. For example, a financial analysis tool might use JSON-formatted outputs to feed directly into visualization components, while a creative writing assistant might leverage markdown to immediately display formatted content.

## Further Reading

 - [Amazon Bedrock Workshop](https://catalog.us-east-1.prod.workshops.aws/workshops/a4bdb007-5600-4368-81c5-ff5b4154f518/en-US){:target="_blank" rel="noopener noreferrer"}
 - [GitHub: AWS Bedrock Samples](https://github.com/aws-samples/amazon-bedrock-samples){:target="_blank" rel="noopener noreferrer"}

## Contributors

Author/s:

 - Markus Bestehorn - Tech Lead Generative AI EMEA 

Primary Reviewers:

 - Yibo Liang - Generative AI Specialist SA 
 - Emily Ransley - Generative AI Specialist SA 

Additional Reviewer/s: 

 - Ana-Maria Olaru - Sr. Program Manager 
 - Andrew Hood - Head of Program Development 
 - Dominic Murphy - Sr Mgr, Applied AI Architecture 
 - Gareth Faires - Sr Generative AI Specialist SA 
